{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from scipy.misc import imread\n",
    "from skimage.feature import hog\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lessons_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "def confusion_matrix(true_y, pred_y, labels):\n",
    "    c_matrix = metrics.confusion_matrix(true_y, pred_y)\n",
    "\n",
    "    confusion_table = []\n",
    "    first_row = [\"C.Matrix\"] + labels + [\"ACTUAL\"] + [\"RECALL\"]\n",
    "    confusion_table.append(first_row)\n",
    "\n",
    "    recall = metrics.recall_score(true_y, pred_y, average=None)\n",
    "    for r, row in enumerate(c_matrix):\n",
    "        new_row = [labels[r]]\n",
    "        new_row.extend(row)\n",
    "        new_row.append(sum(row))\n",
    "        new_row.append(recall[r])\n",
    "        confusion_table.append(new_row)\n",
    "\n",
    "    new_row = [\"PREDICTED\"]\n",
    "    for l in labels:\n",
    "        new_row.append(len([t for t in pred_y if t == l]))\n",
    "    new_row.append(len(true_y))\n",
    "    new_row.append(metrics.recall_score(true_y, pred_y, average='macro'))\n",
    "    confusion_table.append(new_row)\n",
    "\n",
    "    new_row = [\"PRECISION\"]\n",
    "    new_row.extend(metrics.precision_score(true_y, pred_y, average=None))\n",
    "    new_row.append(metrics.precision_score(true_y, pred_y, average='macro'))\n",
    "    new_row.append(metrics.f1_score(true_y, pred_y, average='macro'))\n",
    "    confusion_table.append(new_row)\n",
    "\n",
    "    confusion_table = pd.DataFrame(confusion_table)\n",
    "    return confusion_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for root, dirs, files in os.walk(\"dataset/vehicles\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\"):\n",
    "                X.append(imread(os.path.join(root, file)))\n",
    "                y.append(1)\n",
    "            \n",
    "    for root, dirs, files in os.walk(\"dataset/non-vehicles\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\"):\n",
    "                X.append(imread(os.path.join(root, file)))\n",
    "                y.append(0)\n",
    "                \n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(img, orient=9, pix_per_cell=8, cell_per_block=2, spatial_size=(16, 16), hist_bins=32):\n",
    "    \n",
    "    # convert image into desired format\n",
    "    img = img.astype(np.float32) / 255\n",
    "    img = convert_color(img, conv='RGB2YCrCb')\n",
    "    \n",
    "    # extract channels\n",
    "    ch1 = img[:,:,0]\n",
    "    ch2 = img[:,:,1]\n",
    "    ch3 = img[:,:,2]\n",
    "                    \n",
    "    # extract hog features\n",
    "    hog1 = get_hog_features(\n",
    "        ch1, orient, pix_per_cell, cell_per_block, feature_vec=False).ravel()\n",
    "    hog2 = get_hog_features(\n",
    "        ch2, orient, pix_per_cell, cell_per_block, feature_vec=False).ravel()\n",
    "    hog3 = get_hog_features(\n",
    "        ch3, orient, pix_per_cell, cell_per_block, feature_vec=False).ravel()\n",
    "    hog_features = np.hstack((hog1, hog2, hog3))\n",
    "    \n",
    "    # extract spatial features  \n",
    "    spatial_features = bin_spatial(img, size=spatial_size)\n",
    "    \n",
    "    # extract color histogram features\n",
    "    hist_features = color_hist(img, nbins=hist_bins)\n",
    "    \n",
    "    # stack extracted features\n",
    "    features = np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (17760, 6156)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C.Matrix</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ACTUAL</td>\n",
       "      <td>RECALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2968.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2974</td>\n",
       "      <td>0.997983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2855.000000</td>\n",
       "      <td>2887</td>\n",
       "      <td>0.988916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PREDICTED</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>2861.000000</td>\n",
       "      <td>5861</td>\n",
       "      <td>0.993449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRECISION</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.997903</td>\n",
       "      <td>0.993618</td>\n",
       "      <td>0.993514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0            1            2         3         4\n",
       "0   C.Matrix     0.000000     1.000000    ACTUAL    RECALL\n",
       "1          0  2968.000000     6.000000      2974  0.997983\n",
       "2          1    32.000000  2855.000000      2887  0.988916\n",
       "3  PREDICTED  3000.000000  2861.000000      5861  0.993449\n",
       "4  PRECISION     0.989333     0.997903  0.993618  0.993514"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = get_dataset()\n",
    "\n",
    "# vstack is slow, therefore I create a list, which is then converted into numpy array\n",
    "features = []\n",
    "for x in X:\n",
    "    features.append(get_features(x))\n",
    "features = np.asarray(features).squeeze()\n",
    "print(\"Features shape: {}\".format(features.shape))\n",
    "\n",
    "ss = StandardScaler()\n",
    "features = ss.fit_transform(features)\n",
    "\n",
    "# split into training/validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    features, y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "confusion_matrix(y_valid, clf.predict(X_valid), [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save\n",
    "pickle.dump(clf, open(\"svc_pickle.p\", 'wb'))\n",
    "pickle.dump(ss, open(\"scaler_pickle.p\", 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv3",
   "language": "python",
   "name": "cv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
